w <- c(2,4,8)
A*w
A%*%t(w)
A%*%w
w
dim(A)
apply(A, 1, function(x)x*w)
t(apply(A, 1, function(x)*w))
t(apply(A, 1, function(x)x*w))
?glmnet
glmnet
clogitL1
clogitL1::clogitL1
clogitL1::cv.clogitL1
?clogitL1::cv.clogitL1
library(penalizedclr)
library(penalizedclr)
# two groups of predictors
p <- c(8, 20)
# percentage and number of non-null variables
p_nz <- c(0.5, 0.2)
m_nz <- round(p*p_nz, 0)
# number of different strata (case-control pairs)
K <- 100
# number of cases and controls in each stratum (not necessarily 1:1 matching, other designs are also allowed)
n_cases <- 1
n_ctrl <- 1
# generating covariates
X = cbind(matrix(rnorm(p[1] * K * (n_cases + n_ctrl), 0, 1), ncol = p[1]),
matrix(rnorm(p[2] * K * (n_cases + n_ctrl), 0, 2), ncol = p[2]))
# coefficients
beta <- as.matrix(c(rnorm(m_nz[1], 2, 0.8),
rep(0, p[1] - m_nz[1]),
rnorm(m_nz[2], 2, 0.4),
rep(0, p[2] - m_nz[2])), ncol = 1)
beta_stratum <- rep(rnorm(K, 0, 2), each= n_cases+n_ctrl)
# stratum membership
stratum <- rep(1:K, each= n_cases+n_ctrl)
# linear predictor
lin_pred <- beta_stratum + X %*% beta
prob_case <- exp(lin_pred) / (1 + exp(lin_pred))
# generate the response
Y <- rep(0, length(stratum))
data_sim <- as_tibble(data.frame(stratum = stratum,
probability = prob_case,
obs_id = 1 : length(stratum)))
data_sim_cases <- data_sim %>%
group_by(stratum)%>%
sample_n(n_cases, weight = probability)
Y[data_sim_cases$obs_id] <- 1
fit1 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(6,8),
p = p, standardize = TRUE)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
fit2 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(6,2),p = p, standardize = TRUE, alpha = 0.6)
stable1 <- stable.clr(response = Y, B = 50,
penalized = X, stratum = stratum,
lambda.seq = c(4,5), parallel = TRUE)
str(stable1)
hist(stable1$P)
(tab1 <- table(stable = (stable1$P>0.6) * 1, nonzero_index))
(tab1[1,1] +tab1[2,2])/(sum(tab1))
str(stable1)
hist(stable1$P, xlab = "Selection probability", ylab="Frequency")
(tab1 <- table(stable = (stable1$P>0.6) * 1, nonzero_index))
(tab1[1,1] +tab1[2,2])/(sum(tab1))
stable2 <- stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = list(c(4,4), c(4,5)))
# histogram of selection probabilities
hist(stable2$P, xlab = "Selection probability", ylab="Frequency")
# table of true status vs. selection status
(tab2 <- table(stable = (stable2$P>0.65) * 1, nonzero_index))
# classification accuracy
(tab2[1,1] + tab2[2,2])/(sum(tab2))
# plotting selection probabilities for true non-zero (red) and zero (blue) coefficients
s_prob_nonzero <- cut(stable2$P[nonzero_index==1], breaks = seq(0,1, by =0.1), ordered_result = T)
s_prob_zero <- cut(stable2$P[nonzero_index==0], breaks = seq(0,1, by =0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add =T, col = 4 )
pf <- default.pf(X, Y, stratum, nfolds = 10, alpha = 0.3,
standardize = TRUE, p = p, type.step1 = "comb")
pf.list = list(c(1,2), c(2,1), c(1,4), c(1,8), c(8,1), pf$pf)
lambda <- find.default.lambda(response = Y,penalized = X, standardize = TRUE,
stratum = stratum, p = p,
pf.list  = pf.list)
lambda.matrix <- mapply(function (x,y) x*y, lambda, pf.list)
lambda.list <- lapply(seq_len(ncol(lambda.matrix)), function(i) lambda.matrix[,i])
lambda.list
stable2 <- stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = lambda.list)
which(stable2$P>0.6)
which(stable2$P>0.7)
s_prob_nonzero <- cut(stable2$P[nonzero_index==1], breaks = seq(0,1, by =0.1), ordered_result = T)
s_prob_zero <- cut(stable2$P[nonzero_index==0], breaks = seq(0,1, by =0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add =T, col = 4 )
which(stable2$P>0.9)
nonzero_index
which(nonzero_index==1)
pf$pf
# two groups of predictors
p <- c(8, 20)
# percentage and number of non-null variables
p_nz <- c(0.5, 0.2)
m_nz <- round(p*p_nz, 0)
# number of different strata (case-control pairs)
K <- 100
# number of cases and controls in each stratum (not necessarily 1:1 matching, other designs are also allowed)
n_cases <- 1
n_ctrl <- 1
# generating covariates
X = cbind(matrix(rnorm(p[1] * K * (n_cases + n_ctrl), 0, 1), ncol = p[1]),
matrix(rnorm(p[2] * K * (n_cases + n_ctrl), 10, 4), ncol = p[2]))
# coefficients
beta <- as.matrix(c(rnorm(m_nz[1], 2, 0.8),
rep(0, p[1] - m_nz[1]),
rnorm(m_nz[2], 2, 0.4),
rep(0, p[2] - m_nz[2])), ncol = 1)
beta_stratum <- rep(rnorm(K, 0, 2), each= n_cases+n_ctrl)
# stratum membership
stratum <- rep(1:K, each= n_cases+n_ctrl)
# linear predictor
lin_pred <- beta_stratum + X %*% beta
prob_case <- exp(lin_pred) / (1 + exp(lin_pred))
# generate the response
Y <- rep(0, length(stratum))
data_sim <- as_tibble(data.frame(stratum = stratum,
probability = prob_case,
obs_id = 1 : length(stratum)))
data_sim_cases <- data_sim %>%
group_by(stratum)%>%
sample_n(n_cases, weight = probability)
Y[data_sim_cases$obs_id] <- 1
fit1 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(6,8),
p = p, standardize = TRUE)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
fit1 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(2,8), p = p, standardize = TRUE)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
fit2 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(6,2),p = p, standardize = TRUE, alpha = 0.6)
stable1 <- stable.clr(response = Y, B = 50,
penalized = X, stratum = stratum,
lambda.seq = c(4,5), parallel = TRUE)
str(stable1)
hist(stable1$P, xlab = "Selection probability", ylab="Frequency")
(tab1 <- table(stable = (stable1$P>0.6) * 1, nonzero_index))
(tab1[1,1] +tab1[2,2])/(sum(tab1))
stable2 <- stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = list(c(4,4), c(4,5)))
# histogram of selection probabilities
hist(stable2$P, xlab = "Selection probability", ylab="Frequency")
# table of true status vs. selection status
(tab2 <- table(stable = (stable2$P>0.65) * 1, nonzero_index))
# classification accuracy
(tab2[1,1] + tab2[2,2])/(sum(tab2))
# plotting selection probabilities for true non-zero (red) and zero (blue) coefficients
s_prob_nonzero <- cut(stable2$P[nonzero_index==1], breaks = seq(0,1, by =0.1), ordered_result = T)
s_prob_zero <- cut(stable2$P[nonzero_index==0], breaks = seq(0,1, by =0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add =T, col = 4 )
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
# two groups of predictors
p <- c(8, 20)
# percentage and number of non-null variables
p_nz <- c(0.5, 0.2)
m_nz <- round(p*p_nz, 0)
# number of different strata (case-control pairs)
K <- 100
# number of cases and controls in each stratum (not necessarily 1:1 matching, other designs are also allowed)
n_cases <- 1
n_ctrl <- 1
# generating covariates
X = cbind(matrix(rnorm(p[1] * K * (n_cases + n_ctrl), 0, 1), ncol = p[1]),
matrix(rnorm(p[2] * K * (n_cases + n_ctrl), 10, 4), ncol = p[2]))
# coefficients
beta <- as.matrix(c(rnorm(m_nz[1], 2, 0.8),
rep(0, p[1] - m_nz[1]),
rnorm(m_nz[2], 2, 0.4),
rep(0, p[2] - m_nz[2])), ncol = 1)
beta_stratum <- rep(rnorm(K, 0, 2), each= n_cases+n_ctrl)
# stratum membership
stratum <- rep(1:K, each= n_cases+n_ctrl)
# linear predictor
lin_pred <- beta_stratum + X %*% beta
prob_case <- exp(lin_pred) / (1 + exp(lin_pred))
# generate the response
Y <- rep(0, length(stratum))
data_sim <- as_tibble(data.frame(stratum = stratum,
probability = prob_case,
obs_id = 1 : length(stratum)))
data_sim_cases <- data_sim %>%
group_by(stratum)%>%
sample_n(n_cases, weight = probability)
Y[data_sim_cases$obs_id] <- 1
fit1 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(2,8), p = p, standardize = TRUE)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
fit2 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(6,2),p = p, standardize = TRUE, alpha = 0.6)
fit2 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(6,8),p = p, standardize = TRUE, alpha = 0.6)
stable1 <- stable.clr(response = Y, B = 50,
penalized = X, stratum = stratum,
lambda.seq = c(4,5), parallel = TRUE)
str(stable1)
hist(stable1$P, xlab = "Selection probability", ylab="Frequency")
(tab1 <- table(stable = (stable1$P>0.6) * 1, nonzero_index))
(tab1[1,1] +tab1[2,2])/(sum(tab1))
stable2 <- stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = list(c(4,4), c(4,5)))
# histogram of selection probabilities
hist(stable2$P, xlab = "Selection probability", ylab="Frequency")
# table of true status vs. selection status
(tab2 <- table(stable = (stable2$P>0.65) * 1, nonzero_index))
# classification accuracy
(tab2[1,1] + tab2[2,2])/(sum(tab2))
# plotting selection probabilities for true non-zero (red) and zero (blue) coefficients
s_prob_nonzero <- cut(stable2$P[nonzero_index==1], breaks = seq(0,1, by =0.1), ordered_result = T)
s_prob_zero <- cut(stable2$P[nonzero_index==0], breaks = seq(0,1, by =0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add =T, col = 4 )
# two groups of predictors
p <- c(8, 20)
# percentage and number of non-null variables
p_nz <- c(0.5, 0.2)
m_nz <- round(p*p_nz, 0)
# number of different strata (case-control pairs)
K <- 100
# number of cases and controls in each stratum (not necessarily 1:1 matching, other designs are also allowed)
n_cases <- 1
n_ctrl <- 1
# generating covariates
X = cbind(matrix(rnorm(p[1] * K * (n_cases + n_ctrl), 0, 1), ncol = p[1]),
matrix(rnorm(p[2] * K * (n_cases + n_ctrl), 10, 2), ncol = p[2]))
# coefficients
beta <- as.matrix(c(rnorm(m_nz[1], 2, 0.8),
rep(0, p[1] - m_nz[1]),
rnorm(m_nz[2], 2, 0.4),
rep(0, p[2] - m_nz[2])), ncol = 1)
beta_stratum <- rep(rnorm(K, 0, 2), each= n_cases+n_ctrl)
# stratum membership
stratum <- rep(1:K, each= n_cases+n_ctrl)
# linear predictor
lin_pred <- beta_stratum + X %*% beta
prob_case <- exp(lin_pred) / (1 + exp(lin_pred))
# generate the response
Y <- rep(0, length(stratum))
data_sim <- as_tibble(data.frame(stratum = stratum,
probability = prob_case,
obs_id = 1 : length(stratum)))
data_sim_cases <- data_sim %>%
group_by(stratum)%>%
sample_n(n_cases, weight = probability)
Y[data_sim_cases$obs_id] <- 1
fit1 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(2,8), p = p, standardize = TRUE)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
# two groups of predictors
p <- c(8, 20)
# percentage and number of non-null variables
p_nz <- c(0.5, 0.2)
m_nz <- round(p*p_nz, 0)
# number of different strata (case-control pairs)
K <- 100
# number of cases and controls in each stratum (not necessarily 1:1 matching, other designs are also allowed)
n_cases <- 1
n_ctrl <- 1
# generating covariates
X = cbind(matrix(rnorm(p[1] * K * (n_cases + n_ctrl), 0, 1), ncol = p[1]),
matrix(rnorm(p[2] * K * (n_cases + n_ctrl), 0, 2), ncol = p[2]))
# coefficients
beta <- as.matrix(c(rnorm(m_nz[1], 2, 0.8),
rep(0, p[1] - m_nz[1]),
rnorm(m_nz[2], 2, 0.4),
rep(0, p[2] - m_nz[2])), ncol = 1)
beta_stratum <- rep(rnorm(K, 0, 2), each= n_cases+n_ctrl)
# stratum membership
stratum <- rep(1:K, each= n_cases+n_ctrl)
# linear predictor
lin_pred <- beta_stratum + X %*% beta
prob_case <- exp(lin_pred) / (1 + exp(lin_pred))
# generate the response
Y <- rep(0, length(stratum))
data_sim <- as_tibble(data.frame(stratum = stratum,
probability = prob_case,
obs_id = 1 : length(stratum)))
data_sim_cases <- data_sim %>%
group_by(stratum)%>%
sample_n(n_cases, weight = probability)
Y[data_sim_cases$obs_id] <- 1
fit1 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(2,8), p = p, standardize = TRUE)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
fit2 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(6,8),p = p, standardize = TRUE, alpha = 0.6)
stable1 <- stable.clr(response = Y, B = 50,
penalized = X, stratum = stratum,
lambda.seq = c(4,5), parallel = TRUE)
str(stable1)
hist(stable1$P, xlab = "Selection probability", ylab="Frequency")
(tab1 <- table(stable = (stable1$P>0.6) * 1, nonzero_index))
(tab1[1,1] +tab1[2,2])/(sum(tab1))
stable2 <- stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = list(c(4,4), c(4,5)))
# histogram of selection probabilities
hist(stable2$P, xlab = "Selection probability", ylab="Frequency")
# table of true status vs. selection status
(tab2 <- table(stable = (stable2$P>0.65) * 1, nonzero_index))
# classification accuracy
(tab2[1,1] + tab2[2,2])/(sum(tab2))
# plotting selection probabilities for true non-zero (red) and zero (blue) coefficients
s_prob_nonzero <- cut(stable2$P[nonzero_index==1], breaks = seq(0,1, by =0.1), ordered_result = T)
s_prob_zero <- cut(stable2$P[nonzero_index==0], breaks = seq(0,1, by =0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add =T, col = 4 )
pf <- default.pf(X, Y, stratum, nfolds = 10, alpha = 0.3,
standardize = TRUE, p = p, type.step1 = "comb")
pf.list = list(c(1,2), c(2,1), c(1,4), c(1,8), c(8,1), pf$pf)
lambda <- find.default.lambda(response = Y,penalized = X, standardize = TRUE,
stratum = stratum, p = p,
pf.list  = pf.list)
lambda.matrix <- mapply(function (x,y) x*y, lambda, pf.list)
lambda.list <- lapply(seq_len(ncol(lambda.matrix)), function(i) lambda.matrix[,i])
stable2 <- stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = lambda.list)
stable2 <- stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = lambda.list)
which(stable2$P>0.9)
s_prob_nonzero <- cut(stable2$P[nonzero_index==1], breaks = seq(0,1, by =0.1), ordered_result = T)
s_prob_zero <- cut(stable2$P[nonzero_index==0], breaks = seq(0,1, by =0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add =T, col = 4 )
library(penalizedclr)
library(penalizedclr)
pf
?clogitL1
?cvfit
?clogitL1::cv.clogitL1
?default.pf
knitr::opts_chunk$set(
collapse = TRUE,eval = T,
comment = "#>"
)
library(penalizedclr)
set.seed(123)
require(tidyverse)
# two groups of predictors
p <- c(8, 40)
# percentage and number of non-null variables
p_nz <- c(0.5, 0.2)
m_nz <- round(p*p_nz, 0)
# number of different strata (case-control pairs)
K <- 100
# number of cases and controls in each stratum (not necessarily 1:1 matching, other designs are also allowed)
n_cases <- 1
n_ctrl <- 1
# generating covariates
X = cbind(matrix(rnorm(p[1] * K * (n_cases + n_ctrl), 0, 1), ncol = p[1]),
matrix(rnorm(p[2] * K * (n_cases + n_ctrl), 0, 4), ncol = p[2]))
# coefficients
beta <- as.matrix(c(rnorm(m_nz[1], 2, 1),
rep(0, p[1] - m_nz[1]),
rnorm(m_nz[2], 2, 0.8),
rep(0, p[2] - m_nz[2])), ncol = 1)
beta_stratum <- rep(rnorm(K, 0, 2), each= n_cases+n_ctrl)
# stratum membership
stratum <- rep(1:K, each= n_cases+n_ctrl)
# linear predictor
lin_pred <- beta_stratum + X %*% beta
prob_case <- exp(lin_pred) / (1 + exp(lin_pred))
# generate the response
Y <- rep(0, length(stratum))
data_sim <- as_tibble(data.frame(stratum = stratum,
probability = prob_case,
obs_id = 1 : length(stratum)))
data_sim_cases <- data_sim %>%
group_by(stratum)%>%
sample_n(n_cases, weight = probability)
Y[data_sim_cases$obs_id] <- 1
fit1 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(1,4), p = p, standardize = TRUE)
str(fit1)
nonzero_index <- (beta != 0) * 1 #index of nonzero coefficients
table(fitted = (fit1$penalized != 0) * 1, nonzero_index)
fit2 <- penalized.clr(response = Y, penalized = X, stratum = stratum, lambda = c(1,4),p = p, standardize = TRUE, alpha = 0.6)
stable1 <- stable.clr(response = Y, B = 50,
penalized = X, stratum = stratum,
lambda.seq = c(1, 4, 6), parallel = TRUE)
str(stable1)
hist(stable1$P, xlab = "Selection probability", ylab="Frequency")
(tab1 <- table(stable = (stable1$P>0.65) * 1, nonzero_index))
(tab1[1,1] + tab1[2,2])/(sum(tab1))
# plotting selection probabilities for true non-zero (red) and zero (blue) coefficients
s_prob_nonzero <- cut(stable1$P[nonzero_index == 1], breaks = seq(0,1, by = 0.1), ordered_result = T)
s_prob_zero <- cut(stable1$P[nonzero_index == 0], breaks = seq(0,1, by = 0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add =T, col = 4 )
stable2 <- penalizedclr::stable.clr.g(response = Y, p = p,  standardize = TRUE,
penalized = X, stratum = stratum,
lambda.list = list(c(4,1), c(1,4)))
# histogram of selection probabilities
hist(stable2$P, xlab = "Selection probability", ylab="Frequency")
# table of true status vs. selection status
(tab2 <- table(stable = (stable2$P>0.65) * 1, nonzero_index))
# classification accuracy
(tab2[1,1] + tab2[2,2])/(sum(tab2))
# plotting selection probabilities for true non-zero (red) and zero (blue) coefficients
s_prob_nonzero <- cut(stable2$P[nonzero_index == 1], breaks = seq(0,1, by = 0.1), ordered_result = T)
s_prob_zero <- cut(stable2$P[nonzero_index == 0], breaks = seq(0,1, by = 0.1), ordered_result = T)
barplot(table(s_prob_nonzero), col = 2)
barplot(table(s_prob_zero), add = T, col = 4 )
pf <- default.pf(X, Y, stratum, nfolds = 10, alpha = 0.3,
standardize = TRUE, p = p, type.step1 = "comb")
pf
pf.list = list(pf$pf)
pf.list
lambda <- find.default.lambda(response = Y,penalized = X, standardize = TRUE,
stratum = stratum, p = p,
pf.list  = pf.list)
lambda
lambda.matrix <- mapply(function (x,y) x*y, lambda, pf.list)
lambda.list <- lapply(seq_len(ncol(lambda.matrix)), function(i) lambda.matrix[,i])
lambda.list
library(penalizedclr)
library(penalizedclr)
?default.pf
?default.pf1
library(penalizedclr)
?default.pf
library(penalizedclr)
?default.pf
library(penalizedclr)
?default.pf
library(penalizedclr)
?default.pf
set.seed(123)
# simulate covariates (pure noise in two blocks of 20 and 80 variables)
X <- cbind(matrix(rnorm(4000, 0, 1), ncol = 20), matrix(rnorm(16000, 2, 0.6), ncol = 80))
p <- c(20,80)
pf.list <- list(c(0.5, 1), c(2, 0.9))
# stratum membership
stratum <- sort(rep(1:100, 2))
# the response
Y <- rep(c(1, 0), 100)
lambda.list <- find.default.lambda(response = Y,
penalized = X, stratum = stratum, p = p, pf.list = pf.list)}
lambda.list <- find.default.lambda(response = Y,
penalized = X, stratum = stratum, p = p, pf.list = pf.list)
lambda.list
ambda.seq <- find.default.lambda(response = Y,
penalized = X, stratum = stratum)
ambda.seq
find.default.lambda <- function(response, stratum, penalized,
unpenalized = NULL,
alpha = 1,
p = NULL,
standardize = TRUE,
event,
pf.list = NULL,
nfolds = 10){
if (missing(event) && is.factor(response)) event <- levels(response)[1]
if (is.factor(response)) response <- (response == event) * 1
if (!is.null(unpenalized)) {X <- cbind(unpenalized, penalized)
nc <- ncol(unpenalized)} else{
X <- penalized
nc <- 0
}
#if(standardize == T) X <- apply(X, 2, function(x)
#  x/sqrt((length(x)-1)/length(x)*var(x)))
if (standardize == T) X <- scale(X)
if(missing(p) | is.null(p)){
lambda.seq <- default.lambda(X, response, stratum, alpha, nfolds = nfolds)
} else{
if (missing(pf.list)) stop("Argument pf.list is missing with no default.")
lambda.seq <- list()
for(i in 1:length(pf.list)){
w <- as.numeric(pf.list[[i]])
weights <- c(rep(1, nc),
rep(1/w,  p))
X_w <- t(apply(X, 1, function(x)  x* weights))
lambda.seq[[i]] <- default.lambda(X = X_w,
response,
stratum,
alpha,
nfolds = nfolds)
}
}
return("lambda.seq" = lambda.seq)
}
library(penalizedclr)
?default.lambda
?find.default.lambda
?find.default.lambda
library(penalizedclr)
?find.default.lambda
library(penalizedclr)
6*2*2*3
